<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ai/ml/数据集和模型评估/模型评价" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">模型评价 | Panovista</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wangenius.github.io/en/docs/ai/ml/数据集和模型评估/模型评价"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="模型评价 | Panovista"><meta data-rh="true" name="description" content="前面的内容将机器学习介绍为“从经验中学习”。 这里所说的“学习”，是指自主提高模型完成某些任务的效能。 但是，什么才算真正的提高呢？ 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为目标函数（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。 但这只是一个惯例，我们也可以取一个新的函数，优化到它的最高点。 这两个函数本质上是相同的，只是翻转一下符号。"><meta data-rh="true" property="og:description" content="前面的内容将机器学习介绍为“从经验中学习”。 这里所说的“学习”，是指自主提高模型完成某些任务的效能。 但是，什么才算真正的提高呢？ 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为目标函数（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。 但这只是一个惯例，我们也可以取一个新的函数，优化到它的最高点。 这两个函数本质上是相同的，只是翻转一下符号。"><link data-rh="true" rel="icon" href="/en/img/panovista.svg"><link data-rh="true" rel="canonical" href="https://wangenius.github.io/en/docs/ai/ml/数据集和模型评估/模型评价"><link data-rh="true" rel="alternate" href="https://wangenius.github.io/en/docs/ai/ml/数据集和模型评估/模型评价" hreflang="en"><link data-rh="true" rel="alternate" href="https://wangenius.github.io/docs/ai/ml/数据集和模型评估/模型评价" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://wangenius.github.io/docs/ai/ml/数据集和模型评估/模型评价" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/en/blog/rss.xml" title="Panovista RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/en/blog/atom.xml" title="Panovista Atom Feed">






<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/en/assets/css/styles.9d024903.css">
<script src="/en/assets/js/runtime~main.3aab34f3.js" defer="defer"></script>
<script src="/en/assets/js/main.a3becc44.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/panovista.png" alt="logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/panovista.png" alt="logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">panovista</b></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">DSA</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/en/docs/dsa/ds/概述">算法和数据结构</a></li><li><a class="dropdown__link" href="/en/docs/dsa/leetcode/字符串相关/公共字段">leetcode刷题</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">计算机原理</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/en/docs/cs/co/概述">组成原理</a></li><li><a class="dropdown__link" href="/en/docs/cs/db/SQL">数据库</a></li><li><a class="dropdown__link" href="/en/docs/cs/os/概述">操作系统</a></li><li><a class="dropdown__link" href="/en/docs/cs/web/LAN和以太网">计算机网络</a></li><li><a class="dropdown__link" href="/en/docs/more/git/安装和设置">Git</a></li><li><a class="dropdown__link" href="/en/docs/cs/se/概述">软件工程</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">AI</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/en/docs/ai/ml/概述">机器学习</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">语言</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/en/docs/lang/cpp/简介">C++</a></li><li><a class="dropdown__link" href="/en/docs/lang/python/概述">Python</a></li><li><a class="dropdown__link" href="/en/docs/lang/rust/简介">Rust</a></li><li><a class="dropdown__link" href="/en/docs/lang/ts/CSS">TypeScript</a></li><li><a class="dropdown__link" href="/en/docs/lang/compile/概述">编译原理</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">更多</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/en/docs/more/math/space">数学</a></li><li><a class="dropdown__link" href="/en/docs/more/tools/scoop">工具和工作流</a></li></ul></div><a class="navbar__item navbar__link" href="/en/docs/opus/overview">作品集</a><a class="navbar__item navbar__link" href="/en/blog">博客</a><a class="navbar__item navbar__link" href="/en/docs/about/关于我">关于</a><a href="https://github.com/wangenius/wangenius.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/en/"><img src="/en/img/panovista.png" alt="logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/panovista.png" alt="logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b>panovista</b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/ai/ml/概述">概述</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active">数据集和模型评估</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/docs/ai/ml/数据集和模型评估/模型评价">模型评价</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/数据集和模型评估/数据集和训练集">数据集和训练集</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">监督学习及相关算法</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/贝叶斯定理">贝叶斯定理</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/决策树">决策树</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/支持向量机">支持向量机</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/特征工程">特征工程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/KNN算法">KNN算法</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/回归算法">回归算法</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/监督学习及相关算法/逻辑回归">逻辑回归</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/ai/ml/优化算法">优化算法</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">强化学习</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/强化学习/强化学习简介">强化学习简介</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">无监督学习</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/无监督学习/聚类和降维算法">聚类和降维算法</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">神经网络和深度学习</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/神经网络和深度学习/深度学习">深度学习</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/神经网络和深度学习/神经网络">神经网络</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/ai/ml/神经网络和深度学习/卷积神经网络">卷积神经网络</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">数据集和模型评估</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">模型评价</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>模型评价</h1>
<p>前面的内容将机器学习介绍为“从经验中学习”。 这里所说的“学习”，是指自主提高模型完成某些任务的效能。 但是，什么才算真正的提高呢？ 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为目标函数（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。 但这只是一个惯例，我们也可以取一个新的函数，优化到它的最高点。 这两个函数本质上是相同的，只是翻转一下符号。</p>
<p>当任务在试图预测数值时，最常见的损失函数是平方误差（squared error），即预测值与实际值之差的平方。 当试图解决分类问题时，最常见的目标函数是最小化错误率，即预测与实际情况不符的样本比例。 有些目标函数（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其他复杂性难以直接优化。 在这些情况下，通常会优化替代目标。</p>
<p>通常，损失函数是根据模型参数定义的，并取决于数据集。 在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为训练数据集（training dataset，或称为训练集（training set））。 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为测试数据集（test dataset，或称为测试集（test set））。</p>
<p>综上所述，可用数据集通常可以分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。 然后我们观察模型在这两部分数据集的性能。 “一个模型在训练数据集上的性能”可以被想象成“一个学生在模拟考试中的分数”。 这个分数用来为一些真正的期末考试做参考，即使成绩令人鼓舞，也不能保证期末考试成功。 换言之，测试性能可能会显著偏离训练性能。 当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为过拟合（overfitting）的。 就像在现实生活中，尽管模拟考试考得很好，真正的考试不一定百发百中。</p>
<ol>
<li>分类: 精确率 召回率 准确率 F值 ROC-AUC 混淆矩阵 PRC</li>
<li>回归<!-- -->
<ol>
<li>RMSE平方根误差</li>
<li>MAE平均绝对误差</li>
<li>MSE平均平方误差</li>
</ol>
</li>
<li>聚类<!-- -->
<ol>
<li>兰德指数</li>
<li>互信息</li>
<li>轮廓系数</li>
</ol>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="batch的大小对训练的影响">batch的大小对训练的影响<a href="#batch的大小对训练的影响" class="hash-link" aria-label="Direct link to batch的大小对训练的影响" title="Direct link to batch的大小对训练的影响">​</a></h2>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="生成模型和判别模型的 区别">生成模型和判别模型的区别<a href="#生成模型和判别模型的区别" class="hash-link" aria-label="Direct link to 生成模型和判别模型的区别" title="Direct link to 生成模型和判别模型的区别">​</a></h2>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="扩散模型">扩散模型<a href="#扩散模型" class="hash-link" aria-label="Direct link to 扩散模型" title="Direct link to 扩散模型">​</a></h2>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="什么是多模态">什么是多模态<a href="#什么是多模态" class="hash-link" aria-label="Direct link to 什么是多模态" title="Direct link to 什么是多模态">​</a></h2>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="什么是大模型">什么是大模型<a href="#什么是大模型" class="hash-link" aria-label="Direct link to 什么是大模型" title="Direct link to 什么是大模型">​</a></h2>
<p>GPT: 使用transformer架构, 依赖于自注意力机制.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="模型">模型<a href="#模型" class="hash-link" aria-label="Direct link to 模型" title="Direct link to 模型">​</a></h2>
<p>大多数机器学习会涉及到数据的转换。 比如一个“摄取照片并预测笑脸”的系统。再比如通过摄取到的一组传感器读数预测读数的正常与异常程度。 虽然简单的模型能够解决如上简单的问题，但本书中关注的问题超出了经典方法的极限。 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。 在讨论深度模型的过程中，本书也将提及一些传统方法。</p>
<p>我们以房价预估为例，讲述一下涉及的概念。</p>
<ul>
<li>训练集（Training Set）：帮助训练模型，简单的说就是通过训练集的数据让确定拟合曲线的参数。</li>
<li>测试集（Test Set）：为了测试已经训练好的模型的精确度。</li>
</ul>
<p>当然，test set这并不能保证模型的正确性，只是说相似的数据用此模型会得出相似的结果。因为在训练模型的时候，参数全是根据现有训练集里的数据进行修正、拟合，有可能会出现过拟合的情况，即这个参数仅对训练集里的数据拟合比较准确，这个时候再有一个数据需要利用模型预测结果，准确率可能就会很差。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="经验误差">经验误差<a href="#经验误差" class="hash-link" aria-label="Direct link to 经验误差" title="Direct link to 经验误差">​</a></h3>
<p>在训练集的数据上进行学习。模型在训练集上的误差称为「经验误差」（Empirical Error）。但是经验误差并不是越小越好，因为我们希望在新的没有见过的数据上，也能有好的预估结果。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="过拟合">过拟合<a href="#过拟合" class="hash-link" aria-label="Direct link to 过拟合" title="Direct link to 过拟合">​</a></h2>
<p>过拟合，指的是模型在训练集上表现的很好，但是在交叉验证集合测试集上表现一般，也就是说模型对未知样本的预测表现一般，泛化（Generalization）能力较差。</p>
<p>如何防止过拟合呢？一般的方法有Early Stopping、数据集扩增（Data Augmentation）、正则化、Dropout等。</p>
<p>正则化：指的是在目标函数后面添加一个正则化项，一般有L1正则化与L2正则化。L1正则是基于L1范数，即在目标函数后面加上参数的L1范数和项，即参数绝对值和与参数的积项。</p>
<p>数据集扩增：即需要得到更多的符合要求的数据，即和已有的数据是独立同分布的，或者近似独立同分布的。一般方法有：从数据源头采集更多数据、复制原有数据并加上随机噪声、重采样、根据当前数据集估计数据分布参数，使用该分布产生更多数据等。</p>
<p>DropOut：通过修改神经网络本身结构来实现的。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="偏差">偏差<a href="#偏差" class="hash-link" aria-label="Direct link to 偏差" title="Direct link to 偏差">​</a></h2>
<p>偏差（Bias），它通常指的是模型拟合的偏差程度。给定无数套训练集而期望拟合出来的模型就是平均模型。偏差就是真实模型和平均模型的差异。</p>
<p>简单模型是一组直线，平均之后得到的平均模型是一条直的虚线，与真实模型曲线的差别较大（灰色阴影部分较大）。因此，简单模型通常高偏差 。</p>
<p>复杂模型是一组起伏很大波浪线，平均之后最大值和最小组都会相互抵消，和真实模型的曲线差别较小，因此复杂模型通常低偏差（见黄色曲线和绿色虚线几乎重合）。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="方差">方差<a href="#方差" class="hash-link" aria-label="Direct link to 方差" title="Direct link to 方差">​</a></h2>
<p>方差（Variance），它通常指的是模型的平稳程度（简单程度）。简单模型的对应的函数如出一辙，都是水平直线，而且平均模型的函数也是一条水平直线，因此简单模型的方差很小，并且对数据的变动不敏感。复杂模型的对应的函数千奇百怪，毫无任何规则，但平均模型的函数也是一条平滑的曲线，因此复杂模型的方差很大，并且对数据的变动很敏感。</p>
<table><thead><tr><th>模型</th><th>偏差</th><th>方差</th><th>拟合情况</th></tr></thead><tbody><tr><td>简单模型</td><td>大</td><td>小</td><td>欠拟合</td></tr><tr><td>复杂模型</td><td>小</td><td>大</td><td>过拟合</td></tr></tbody></table>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="指标">指标<a href="#指标" class="hash-link" aria-label="Direct link to 指标" title="Direct link to   指标">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="回归问题">回归问题<a href="#回归问题" class="hash-link" aria-label="Direct link to 回归问题" title="Direct link to 回归问题">​</a></h3>
<p>关于模型「好坏」的判断，不仅取决于算法和数据，还取决于当前任务需求。回归问题常用的性能度量指标有：平均绝对误差、均方误差、均方根误差、R平方等。</p>
<p>平均绝对误差（Mean Absolute Error，MAE），又叫平均绝对离差，是所有标签值与回归模型预测值的偏差的绝对值的平均。
平均绝对百分误差（Mean Absolute Percentage Error，MAPE）是对MAE的一种改进，考虑了绝对误差相对真实值的比例。
均方误差（Mean Square Error，MSE）相对于平均绝对误差而言，均方误差求的是所有标签值与回归模型预测值的偏差的平方的平均。
均方根误差（Root-Mean-Square Error，RMSE），也称标准误差，是在均方误差的基础上进行开方运算。RMSE会被用来衡量观测值同真值之间的偏差。
R平方，决定系数，反映因变量的全部变异能通过目前的回归模型被模型中的自变量解释的比例。比例越接近于1，表示当前的回归模型对数据的解释越好，越能精确描述数据的真实分布。</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="分类问题">分类问题<a href="#分类问题" class="hash-link" aria-label="Direct link to 分类问题" title="Direct link to 分类问题">​</a></h3>
<p>分类问题常用的性能度量指标包括错误率（Error Rate）、精确率（Accuracy）、查准率（Precision）、查全率（Recall）、F1、ROC曲线、AUC曲线和R平方等。更详细的内容可见 模型评估方法与准则</p>
<p>错误率：分类错误的样本数占样本总数的比例。
精确率：分类正确的样本数占样本总数的比例。
查准率（也称准确率），即在检索后返回的结果中，真正正确的个  数占你认为是正确的结果的比例。
查全率（也称召回率），即在检索结果中真正正确的个数，占整个数据集（检索到的和未检索到的）中真正正确个数的比例。
F1是一个综合考虑查准率与查全率的度量，其基于查准率与查全率的调和平均定义：即：F1度量的一般形式-Fβ，能让我们表达出对查准率、查全率的不同偏好。</p>
<p>ROC曲线（Receiver Operating Characteristic Curve）全称是「受试者工作特性曲线」。综合考虑了概率预测排序的质量，体现了学习器在不同任务下的「期望泛化性能」的好坏。ROC曲线的纵轴是「真正例率」（TPR），横轴是「假正例率」（FPR）。</p>
<p>AUC（Area Under ROC Curve）是ROC曲线下面积，代表了样本预测的排序质量。</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="评估方法">评估方法<a href="#评估方法" class="hash-link" aria-label="Direct link to 评估方法" title="Direct link to 评估方法">​</a></h2>
<p>我们手上没有未知的样本，如何可靠地评估？关键是要获得可靠的「测试集数据」（Test Set），即测试集（用于评估）应该与训练集（用于模型学习）「互斥」。</p>
<p>常见的评估方法有：留出法（Hold-out）、交叉验证法（ Cross Validation）、自助法（Bootstrap）。更详细的内容可见 模型评估方法与准则</p>
<p>留出法（Hold-out）是机器学习中最常见的评估方法之一，它会从训练数据中保留出验证样本集，这部分数据不用于训练，而用于模型评估。</p>
<p>机器学习中，另外一种比较常见的评估方法是交叉验证法（ Cross Validation）。k 折交叉验证对 k 个不同分组训练的结果进行平均来减少方差，因此模型的性能对数据的划分就不那么敏感，对数据的使用也会更充分，模型评估结果更加稳定。</p>
<p>自助法（Bootstrap）是一种用小样本估计总体值的一种非参数方法，在进化和生态学研究中应用十分广泛。</p>
<p>Bootstrap通过有放回抽样生成大量的伪样本，通过对伪样本进行计算，获得统计量的分布，从而估计数据的整体分布。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wangenius/wangenius.github.io/tree/master/docs/ai/ml/数据集和模型评估/模型评价.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/docs/ai/ml/概述"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">概述</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/docs/ai/ml/数据集和模型评估/数据集和训练集"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">数据集和训练集</div></a></nav></div><div>Loading Comments...</div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#batch的大小对训练的影响" class="table-of-contents__link toc-highlight">batch的大小对训练的影响</a></li><li><a href="#生成模型和判别模型的区别" class="table-of-contents__link toc-highlight">生成模型和判别模型的区别</a></li><li><a href="#扩散模型" class="table-of-contents__link toc-highlight">扩散模型</a></li><li><a href="#什么是多模态" class="table-of-contents__link toc-highlight">什么是多模态</a></li><li><a href="#什么是大模型" class="table-of-contents__link toc-highlight">什么是大模型</a></li><li><a href="#模型" class="table-of-contents__link toc-highlight">模型</a><ul><li><a href="#经验误差" class="table-of-contents__link toc-highlight">经验误差</a></li></ul></li><li><a href="#过拟合" class="table-of-contents__link toc-highlight">过拟合</a></li><li><a href="#偏差" class="table-of-contents__link toc-highlight">偏差</a></li><li><a href="#方差" class="table-of-contents__link toc-highlight">方差</a></li><li><a href="#指标" class="table-of-contents__link toc-highlight">指标</a><ul><li><a href="#回归问题" class="table-of-contents__link toc-highlight">回归问题</a></li><li><a href="#分类问题" class="table-of-contents__link toc-highlight">分类问题</a></li></ul></li><li><a href="#评估方法" class="table-of-contents__link toc-highlight">评估方法</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">知识库</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/en/docs/about/致明日的舞">致明日的舞</a></li><li class="footer__item"><a class="footer__link-item" href="/en/docs/cs/os/概述">操作系统基础</a></li><li class="footer__item"><a class="footer__link-item" href="/en/docs/dsa/ds/概述">数据结构</a></li><li class="footer__item"><a class="footer__link-item" href="/en/docs/lang/rust/简介">Rust</a></li><li class="footer__item"><a class="footer__link-item" href="/en/docs/cs/db/概述">数据库</a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://weibo.com/u/6320492937" target="_blank" rel="noopener noreferrer" class="footer__link-item">微博<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://space.bilibili.com/247967944" target="_blank" rel="noopener noreferrer" class="footer__link-item">bilibili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.zhihu.com/people/wangenius" target="_blank" rel="noopener noreferrer" class="footer__link-item">知乎<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/wangenius" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">更多</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/en/docs/about/关于我">关于我</a></li><li class="footer__item"><a class="footer__link-item" href="/en/blog">博客</a></li><li class="footer__item"><a href="https://github.com/wangenius/wangenius.github.io/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">讨论<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/wangenius/wangenius.github.io/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQ<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 吕麓弥章, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>